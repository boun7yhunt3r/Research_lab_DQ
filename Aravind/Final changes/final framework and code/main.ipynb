{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import data_quality as dq\n",
    "import openpyxl\n",
    "import panel as pn\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Framework.data_quality import DataQualityChecker\n",
    "from Framework.improve_dq import Improve_DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to use ZIP archive that was already closed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m csv_file \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39mD:/Github/Merged code/AirQualityUCI.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(csv_file, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, decimal\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aravind R K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\zipfile.py:1501\u001b[0m, in \u001b[0;36mZipFile.open\u001b[1;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpwd is only supported for reading files\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp:\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1502\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempt to use ZIP archive that was already closed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[39m# Make sure we have an info object\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(name, ZipInfo):\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# 'name' is already an info object\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to use ZIP archive that was already closed"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(\"D:/Github/Merged code/AirQualityUCI.csv\", sep=\";\", decimal=\",\")\n",
    "\n",
    "# Create an instance of DataQualityChecker\n",
    "checker = DataQualityChecker(data)\n",
    "\n",
    "# Creatre an instance of Improve_DQ\n",
    "improve = Improve_DQ(data) \n",
    "\n",
    "\n",
    "columns_of_interest = [\"CO(GT)\", \"PT08.S2(NMHC)\", \"NOx(GT)\",\n",
    "                       ]\n",
    "\n",
    "\n",
    "# Add expectations and calculate scores\n",
    "Consistency_scores = checker.calculate_consistency_scores(columns_of_interest)\n",
    "Relevancy_scores = checker.calculate_relevancy_scores(columns_of_interest, 3)\n",
    "\n",
    "print(\"min max \")\n",
    "print(checker.check_missing_data())\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "fig = checker.visualize_time_series(columns_of_interest)\n",
    "\n",
    "if fig:\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"The column '{columns_of_interest}' does not exist in the dataset.\")\n",
    "\n",
    "print(\"smooth_outliers\")\n",
    "smooth_outliers_Data = improve.smooth_outliers(columns_of_interest=columns_of_interest)\n",
    "print(smooth_outliers_Data)\n",
    "smooth_outliers_Data.to_excel('output.xlsx', index=False)\n",
    "\n",
    "\n",
    "print(\"Handling duplicates\")\n",
    "print(improve.handle_duplicates())\n",
    "\n",
    "print(\"Smoothen outlier\")\n",
    "print(improve.smooth_outliers())\n",
    "\n",
    "\n",
    "print(\"Check completeness\")\n",
    "print(checker.check_completeness())\n",
    "\n",
    "print(\"Check duplicates\")\n",
    "print(checker.check_duplicates())\n",
    "\n",
    "print(\"Check skewtness\")\n",
    "print(checker.check_skewness())\n",
    "\n",
    "print(\"Check missing data\")\n",
    "print(checker.check_missing_data())\n",
    "\n",
    "\n",
    "print(\"Check check_stationarity column\")\n",
    "print(checker.check_stationarity()) \"\"\"\n",
    "\n",
    "# Define columns of interest\n",
    "all_columns = data.columns.tolist()\n",
    "\n",
    "# Create interactive dropdown for selecting columns\n",
    "column_dropdown = pn.widgets.MultiChoice(\n",
    "    name=\"Select Columns of Interest\",\n",
    "    options=all_columns\n",
    ")\n",
    "\n",
    "# Create placeholders for the plots and indicators\n",
    "fig_consistency = pn.pane.Plotly()\n",
    "fig_relevancy = pn.pane.Plotly()\n",
    "circle_overall_consistency = pn.pane.Plotly()\n",
    "circle_overall_relevancy = pn.pane.Plotly()\n",
    "\n",
    "# Create a function to update plots and scores\n",
    "def update_plots(event):\n",
    "    selected_columns = column_dropdown.value\n",
    "    selected_columns = [col for col in selected_columns if pd.api.types.is_numeric_dtype(data[col])]\n",
    "    consistency_scores = checker.calculate_consistency_scores(selected_columns)\n",
    "    print(type(consistency_scores))\n",
    "    relevancy_scores = checker.calculate_relevancy_scores(selected_columns, 3)\n",
    "    print(type(relevancy_scores))\n",
    "\n",
    "    consistency_df = pd.DataFrame(consistency_scores, columns=[\"Column\", \"ConsistencyScore\"])\n",
    "    relevancy_df = pd.DataFrame(relevancy_scores, columns=[\"Column\", \"RelevancyScore\"])\n",
    "\n",
    "    # Calculate ConsistencyPercentage as a percentage from 0 to 100\n",
    "    max_consistency_score = max(consistency_df[\"ConsistencyScore\"])\n",
    "    min_consistency_score = min(consistency_df[\"ConsistencyScore\"])\n",
    "    consistency_df[\"ConsistencyPercentage\"] = ((consistency_df[\"ConsistencyScore\"] - min_consistency_score) / (max_consistency_score - min_consistency_score) * 100).round(2)\n",
    "\n",
    "    # Calculate RelevancyPercentage as a percentage from 0 to 100\n",
    "    max_relevancy_score = max(relevancy_df[\"RelevancyScore\"])\n",
    "    min_relevancy_score = min(relevancy_df[\"RelevancyScore\"])\n",
    "    relevancy_df[\"RelevancyPercentage\"] = ((relevancy_df[\"RelevancyScore\"] - min_relevancy_score) / (max_relevancy_score - min_relevancy_score) * 100).round(2)\n",
    "\n",
    "\n",
    "    print(consistency_df[\"ConsistencyPercentage\"])\n",
    "    print(relevancy_df[\"RelevancyPercentage\"])\n",
    "    fig_consistency.object = px.bar(consistency_df, x=\"Column\", y=\"ConsistencyScore\", title=\"Consistency Scores\")\n",
    "    fig_relevancy.object = px.bar(relevancy_df, x=\"Column\", y=\"RelevancyScore\", title=\"Relevancy Scores\")\n",
    "    \n",
    "    # Calculate overall consistency and relevancy scores\n",
    "    overall_consistency = consistency_df[\"ConsistencyPercentage\"].mean()\n",
    "    overall_relevancy = relevancy_df[\"RelevancyScore\"].sum() / len(selected_columns)\n",
    "    \n",
    "    circle_overall_consistency.object = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=overall_consistency,\n",
    "        title=\"Overall Consistency\",\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        gauge={'axis': {'range': [None, 100]}}\n",
    "    ))\n",
    "    \n",
    "    circle_overall_relevancy.object = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\", \n",
    "        value=overall_relevancy,\n",
    "        title=\"Overall Relevancy\",\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        gauge={'axis': {'range': [None, 100]}}\n",
    "    ))\n",
    "\n",
    "# Link the dropdown widget to the update function\n",
    "column_dropdown.param.watch(update_plots, \"value\")\n",
    "\n",
    "# Create the layout\n",
    "layout = pn.Column(\n",
    "    \"# Air Quality Data Quality Dashboard\",\n",
    "    column_dropdown,\n",
    "    \"## Overall Scores\",\n",
    "    pn.Row(\n",
    "        circle_overall_consistency,\n",
    "        circle_overall_relevancy\n",
    "    ),\n",
    "    \"## Consistency Scores\",\n",
    "    fig_consistency,\n",
    "    \"## Relevancy Scores\",\n",
    "    fig_relevancy\n",
    ")\n",
    "%matplotlib\n",
    "# Display the layout\n",
    "layout.servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
